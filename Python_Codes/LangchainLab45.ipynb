{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import Extra\n",
    "import requests\n",
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS # type: ignore\n",
    "from langchain_ollama import OllamaEmbeddings # type: ignore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"token\"] = \"Bearer token|123675a6-95f6-4fb7-bc95-30095472ae3a|02de311fd83421a7fd637bf34dc8f959caa29f39888d2919e4b9640a2220224b\"\n",
    "token = os.environ[\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill1=\"Core Java L1\"\n",
    "skill2=\"Spring Boot L2\"\n",
    "skill3=\"Hibernate L3\"\n",
    "skill4=\"Selenium L4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ClassVar\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "class LlamaLLM(LLM):\n",
    "    llm_url: ClassVar[str] = 'https://api.lab45.ai/v1.1/skills/completion/query'\n",
    "    \n",
    "    backend:        Optional[str]   = 'gpt-35-turbo-16k'\n",
    "    temp:           Optional[float] = 0.7\n",
    "    top_p:          Optional[float] = 0.1\n",
    "    top_k:          Optional[int]   = 40\n",
    "    n_batch:        Optional[int]   = 8\n",
    "    n_threads:      Optional[int]   = 4\n",
    "    n_predict:      Optional[int]   = 256\n",
    "    max_tokens:     Optional[int]   = 256\n",
    "    repeat_last_n:  Optional[int]   = 64\n",
    "    repeat_penalty: Optional[float] = 1.18\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gpt-35-turbo-16k\"\n",
    "    \n",
    "    @property\n",
    "    def _get_model_default_parameters(self):\n",
    "        return {\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            #\"n_predict\": self.n_predict,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"temperature\": self.temp,\n",
    "            #\"n_batch\": self.n_batch,\n",
    "            #\"repeat_penalty\": self.repeat_penalty,\n",
    "            #\"repeat_last_n\": self.repeat_last_n,\n",
    "        }\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        skill1: str,\n",
    "        user: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "\n",
    "        payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "            \"content\": \"As a skilled Technical Interview Panel with advanced knowledge in technology and data science, your role is to meticulously evaluate a employer job description and provide detailed job description having below points outlined.\",\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use the mentioned skills to generate the job description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced, and L4 means Expert.\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"1. **Job Title and Summary**:\n",
    "            - \"What are the key responsibilities?\"\n",
    "            \n",
    "            2. **Key Responsibilities**:\n",
    "            - \"List the main duties and responsibilities.\"\n",
    "            - \"What are the daily tasks involved?\"\n",
    "\n",
    "            3. **Qualifications and Skills**:\n",
    "            - \"What qualifications are required?\"\n",
    "            - \"List the essential skills needed.\"\n",
    "\n",
    "            4. **Experience Requirements**:\n",
    "            - \"How many years of experience are needed?\"\n",
    "            - \"What type of previous experience is beneficial?\"\n",
    "\n",
    "            \"\"\",\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": skill1,\n",
    "            \"role\": user\n",
    "            }\n",
    "        ],\n",
    "        \"skill_parameters\": {\n",
    "            \"model_name\": \"gpt-35-turbo-16k\",\n",
    "            \"max_output_tokens\": 4096,\n",
    "            \"temperature\": 0,\n",
    "            \"top_k\": 5\n",
    "        },\n",
    "        \"stream_response\": False\n",
    "        }\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\",\"Authorization\": token}\n",
    "\n",
    "        response = requests.post(self.llm_url, json=payload, headers=headers, verify=False)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # print(\"API Response:\", response.json())\n",
    "\n",
    "        return response.json()  # get the response from the API\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"llmUrl\": self.llm_url,\n",
    "            'model_parameters': self._get_model_default_parameters\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LlamaLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd=\"Good in C++ with 5 years of Experience\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = \"\"\"\n",
    "\n",
    "As a skilled Technical Interview Panel with advanced knowledge in technology and data science, your role is to meticulously evaluate a employer job description and provide detailed job description having below points outlined. \n",
    "Your evaluation will involve analyzing the job description for relevant skills, experiences that align with the job requirements. Look for key buzzwords and specific criteria outlined in the job description to determine the detailed job description\n",
    "Your evaluation should be thorough, precise, and objective, ensuring that the most relevant job description is generated based on Skills and Experience mentioned\n",
    "Your evaluation of job description should attract the right candidates\"\n",
    "\n",
    "1. **Job Title and Summary**:\n",
    "   - \"What are the key responsibilities?\"\n",
    "   \n",
    "2. **Key Responsibilities**:\n",
    "   - \"List the main duties and responsibilities.\"\n",
    "   - \"What are the daily tasks involved?\"\n",
    "\n",
    "3. **Qualifications and Skills**:\n",
    "   - \"What qualifications are required?\"\n",
    "   - \"List the essential skills needed.\"\n",
    "\n",
    "4. **Experience Requirements**:\n",
    "   - \"How many years of experience are needed?\"\n",
    "   - \"What type of previous experience is beneficial?\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you're referring to the Selenium Level 4 (L4) autonomous driving system. The L4 designation indicates a high level of automation, where the vehicle can operate without human intervention in certain conditions or environments. This level of automation is just one step below full autonomy (L5), where the vehicle can operate in all conditions without human intervention.\\n\\nSelenium L4 systems are designed to handle most driving situations, but they may still require human intervention in certain scenarios, such as extreme weather conditions or unusual road layouts. These systems typically rely on a combination of sensors, cameras, radar, and advanced algorithms to navigate and make driving decisions.\\n\\nIf you have specific questions about Selenium L4 or autonomous driving systems in general, feel free to ask!\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "#prompt = \"[INST] Question: Who is Albert Einstein? \\n Answer: [/INST]\"\n",
    "prompt = \"Generate Job Description for Good in C++ with 5 years of Experience\"\n",
    "user = \"user\"\n",
    "result = llm._call(skill4,user)\n",
    "parsed_result = result['data']['content'] # type: ignore\n",
    "parser.invoke(parsed_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"you are a bot {name}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build prompt\n",
    "\n",
    "template = \"\"\"[INST] <<SYS>>\n",
    "\n",
    "Answer the question base on the context below.\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "[/INST]\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       verbose=True,\n",
    "                                       retriever=None,\n",
    "                                       #retriever=custom_retriever,\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
