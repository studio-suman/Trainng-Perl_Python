{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import Extra\n",
    "import requests\n",
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS # type: ignore\n",
    "from langchain_ollama import OllamaEmbeddings # type: ignore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "#os.environ[\"token\"] = \"Bearer token|123675a6-95f6-4fb7-bc95-30095472ae3a|02de311fd83421a7fd637bf34dc8f959caa29f39888d2919e4b9640a2220224b\"\n",
    "token = os.getenv(\"TOKEN2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables and endpoints\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "DatasetId = os.getenv(\"DATASETID\")\n",
    "dtname = os.getenv(\"DTNAME\")\n",
    "DatasetID2 = os.getenv(\"DATASETID2\")\n",
    "dtname2 = os.getenv(\"DTNAME2\")\n",
    "\n",
    "# Define the API endpoint for interacting with the agents API\n",
    "agents_endpoint = f\"https://api.lab45.ai/v1.1/agents\"  # The endpoint where agent-related operations are available\n",
    "\n",
    "# Define the API endpoint for interacting with the agents chatAPI\n",
    "agents_endpoint2 = f\"https://api.lab45.ai/v1.1/agent_chat_session/query\"  # The endpoint where agent-related operations are available\n",
    "\n",
    "# Define the API endpoint for preparing the skill, specifically for document completion\n",
    "prepare_endpoint = f\"https://api.lab45.ai/v1.1/skills/doc_completion/prepare\"\n",
    "\n",
    "# Define the API endpoint for querying the document completion skill\n",
    "query_endpoint = f\"https://api.lab45.ai/v1.1/skills/doc_completion/query\"\n",
    "\n",
    "# Set the headers for the request, including content type, accepted response format, and authorization token\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",  # The content type is set to JSON, meaning the body will be JSON-encoded\n",
    "    'Accept': \"text/event-stream, application/json\",  # The client expects either event-stream or JSON as the response format\n",
    "    'Authorization': token  # Replace <api_key> with your actual API key for authentication\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'617b94b4-65b9-4b93-b465-2a3c8b97bf66'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetID2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ClassVar\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "class LlamaLLM(LLM):\n",
    "    llm_url: ClassVar[str] = 'https://api.lab45.ai/v1.1/skills/completion/query'\n",
    "    \n",
    "    backend:        Optional[str]   = 'gpt-35-turbo-16k'\n",
    "    temp:           Optional[float] = 0.7\n",
    "    top_p:          Optional[float] = 0.1\n",
    "    top_k:          Optional[int]   = 40\n",
    "    n_batch:        Optional[int]   = 8\n",
    "    n_threads:      Optional[int]   = 4\n",
    "    n_predict:      Optional[int]   = 256\n",
    "    max_tokens:     Optional[int]   = 256\n",
    "    repeat_last_n:  Optional[int]   = 64\n",
    "    repeat_penalty: Optional[float] = 1.18\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gpt-35-turbo-16k\"\n",
    "    \n",
    "    @property\n",
    "    def _get_model_default_parameters(self):\n",
    "        return {\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            #\"n_predict\": self.n_predict,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"temperature\": self.temp,\n",
    "            #\"n_batch\": self.n_batch,\n",
    "            #\"repeat_penalty\": self.repeat_penalty,\n",
    "            #\"repeat_last_n\": self.repeat_last_n,\n",
    "        }\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        user: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "\n",
    "        payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "            \"content\": prompt,\n",
    "            \"role\": user\n",
    "            }\n",
    "        ],\n",
    "        \"skill_parameters\": {\n",
    "            \"model_name\": \"gpt-35-turbo-16k\",\n",
    "            \"max_output_tokens\": 4096,\n",
    "            \"temperature\": 0,\n",
    "            \"top_k\": 5\n",
    "        },\n",
    "        \"stream_response\": False\n",
    "        }\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\",\"Authorization\": token}\n",
    "\n",
    "        response = requests.post(self.llm_url, json=payload, headers=headers, verify=False)\n",
    "\n",
    "       # print(\"API Response:\", response.json())\n",
    "        response.raise_for_status()\n",
    "\n",
    "        return response.json()  # get the response from the API\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"llmUrl\": self.llm_url,\n",
    "            'model_parameters': self._get_model_default_parameters\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LlamaLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill1=\"Core Java L1\"\n",
    "skill2=\"Spring Boot L2\"\n",
    "skill3=\"Hibernate L3\"\n",
    "skill4=\"Selenium L4\"\n",
    "title=\"Senior Java Full Stack Developer\"\n",
    "user = \"system\"\n",
    "prompt = \"\"\"As a skilled Technical Interview Panel with advanced knowledge in technology and data science, your role is to meticulously evaluate a employer job description and provide detailed job description having below points outlined.\n",
    "            Use the mentioned skills & title to generate the job description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced, and L4 means Expert,\n",
    "            1. **Job Title and Summary**:\n",
    "            - \"What are the key responsibilities?\"\n",
    "            \n",
    "            2. **Key Responsibilities**:\n",
    "            - \"List the main roles and responsibilities as per title and combination of skill along with proficiency\"\n",
    "\n",
    "            3. **Qualifications and Skills**:\n",
    "            - \"What qualifications are required?\"\n",
    "            - \"List the essential skills needed and mention the level of expertise required.\"\n",
    "\n",
    "            4. **Experience Requirements**:\n",
    "            - \"How many years of experience are needed?\"\n",
    "            - \"What type of previous experience is beneficial?\"\n",
    "\n",
    "            \"\"\" + skill1 + skill2 + skill3 + skill4 + title\n",
    "prompt2 =   \"\"\"\n",
    "            Use the mentioned skills & title to generate the job description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced, and L4 means Expert,\n",
    "            Job Title and Summary:\n",
    "            \"What are the key responsibilities?\"\n",
    "            Key Responsibilities:\n",
    "            \"List the main roles and responsibilities as per title and combination of skill along with proficiency\"\n",
    "            Qualifications and Skills:\n",
    "            \"What qualifications are required?\"\n",
    "            \"List the essential skills needed and mention the level of expertise required.\"\n",
    "            Experience Requirements:\n",
    "            \"How many years of experience are needed?\"\n",
    "            \"What type of previous experience is beneficial?\"\n",
    "            \"\"\" + skill1 + skill2 + skill3 + skill4 + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Job Title and Summary**:\\n- Job Title: Senior Java Full Stack Developer\\n- Summary: We are looking for a Senior Java Full Stack Developer to join our team and be responsible for the development and maintenance of our web applications. The ideal candidate should have a strong background in Core Java, Spring Boot, Hibernate, and Selenium.\\n\\n**Key Responsibilities**:\\n- Designing, developing, and maintaining high-quality web applications using Core Java, Spring Boot, Hibernate, and Selenium.\\n- Collaborating with cross-functional teams to define, design, and ship new features.\\n- Writing clean, efficient, and maintainable code.\\n- Troubleshooting and debugging applications to optimize performance.\\n- Implementing security and data protection measures.\\n- Integrating front-end elements built by front-end developers with server-side logic.\\n- Developing and maintaining APIs.\\n- Conducting software analysis, testing, and debugging.\\n- Keeping up-to-date with the latest industry trends and technologies.\\n\\n**Qualifications and Skills**:\\n- Qualifications: Bachelor's degree in Computer Science, Engineering, or a related field.\\n- Essential Skills:\\n  - Core Java (L3)\\n  - Spring Boot (L2)\\n  - Hibernate (L3)\\n  - Selenium (L4)\\n  - Experience with web application development and full stack development.\\n  - Strong understanding of object-oriented programming principles.\\n  - Proficiency in database management and SQL.\\n  - Knowledge of front-end technologies such as HTML, CSS, and JavaScript.\\n  - Familiarity with Agile methodologies and DevOps practices.\\n  - Excellent problem-solving and analytical skills.\\n  - Strong communication and teamwork abilities.\\n\\n**Experience Requirements**:\\n- Years of Experience: 5+ years of experience in Java development and full stack development.\\n- Beneficial Previous Experience: Previous experience in developing and maintaining web applications, working with cross-functional teams, and implementing security measures would be beneficial.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "#prompt = \"What is the current date and time?\"\n",
    "result = llm._call(prompt,user)\n",
    "parsed_result = result['data']['content'] # type: ignore\n",
    "parser.invoke(parsed_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Job Title and Summary**:\\n- Job Title: Senior Java Full Stack Developer\\n- Summary: We are seeking a highly skilled Senior Java Full Stack Developer to join our team. The ideal candidate will have expertise in Core Java, Spring Boot, Hibernate, and Selenium to develop and maintain high-quality web applications.\\n\\n**Key Responsibilities**:\\n- Designing, developing, and maintaining high-quality web applications using Core Java, Spring Boot, Hibernate, and Selenium.\\n- Collaborating with cross-functional teams to define, design, and ship new features.\\n- Writing well-designed, efficient, and testable code.\\n- Troubleshooting and debugging applications to optimize performance.\\n- Implementing security and data protection measures.\\n- Integrating data storage solutions.\\n- Staying updated with emerging technologies and industry trends.\\n\\n**Qualifications and Skills**:\\n- Qualifications: Bachelor's degree in Computer Science, Engineering, or a related field.\\n- Essential Skills:\\n  - Core Java (L3)\\n  - Spring Boot (L2)\\n  - Hibernate (L3)\\n  - Selenium (L4)\\n  - Proficiency in web development technologies such as HTML, CSS, and JavaScript (L3)\\n  - Experience with RESTful APIs and microservices architecture (L3)\\n  - Strong understanding of database management systems (L3)\\n  - Knowledge of software development methodologies and best practices (L3)\\n  - Excellent problem-solving and analytical skills (L3)\\n\\n**Experience Requirements**:\\n- 5+ years of experience in software development.\\n- Previous experience in full stack development and working with Core Java, Spring Boot, Hibernate, and Selenium is beneficial.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = \"Summarize it into 8 to 10 sentences keeping all the key resposibilities and skills profiencies mentioned in the job description.\"\n",
    "result2 = llm._call(prompt,user)\n",
    "parsed_result2 = result2['data']['content'] # type: ignore\n",
    "parser.invoke(parsed_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '9841fb1c-81f0-4481-aeb6-b77bc7f7ea49', 'allow_all_access': False, 'dataset_id': '750d37e1-f77f-4e7a-841a-af8e0f5e1375', 'description': 'JD to Role Cluster Identifier', 'instructions': 'As a skilled Technical Interview Panel with expertise in technology and content writing , your role is to to meticulously \\n evaluate skills and title provided and give detailed job description having below points outlined.\\n Use the mentioned skills along with proficiency  & title to generate the job description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced and L4 means Expert,\\n If Title and skill list is not given the reply the user with this message  I am designed to generate JD based on Title and Skill list given , can you please provide required information\\n 1. **Job Title and Summary**:\\n- What are the key responsibilities?\\n 2. **Key Responsibilities**:\\n - Use title and skill proficiency to explain role and resposibilities , dont mention level like (L1), (L2) instead refer if as beginner, intermidiate etc\\n 3. **Qualifications and Skills**:\\n - Skill with highest proficiency should be given more relavance and rest skill as per proficency can be reference accordingly\\n 4. **Experience Requirements**:\\n - How many years of experience are needed?\\n - What type of previous experience is beneficial?\\n - Use proficincy mentioned in skill to explain experience\\n Once JD is created ,update the JD to latest trends in the market\\nand later use web tool provided to fetch latest information/updates on this JD and update accordingly\\n Finally if user ask to summarise the JD the summarise it in 8 to 10 sentinces keeing title , skills with proficiency information intact', 'max_output_tokens': 256, 'model_name': 'gpt-4', 'name': 'JD_Agentv2', 'owners': ['bf955f58-9ed4-4d5a-9b49-971fc185e5a4'], 'temperature': 0.3, 'tenant_id': 'a919164d-8b7c-43fb-8119-f1997d45ca4f', 'tools': [], 'top_k': 5, 'type': 'Dataset'}\n"
     ]
    }
   ],
   "source": [
    "# Define the payload (request body) for the API call to create an agent, which includes agent details and configuration\n",
    "payload = {\n",
    "    \"allow_all_access\": False,\n",
    "    \"dataset_id\": DatasetId, \n",
    "    \"name\": \"JD_Agentv2\", \n",
    "    \"description\": \"JD to Role Cluster Identifier\", \n",
    "    \"instructions\": \"As a skilled Technical Interview Panel with expertise in technology and content writing , your role is to to meticulously \\n evaluate skills and title provided and give detailed job description having below points outlined.\\n Use the mentioned skills along with proficiency  & title to generate the job description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced and L4 means Expert,\\n If Title and skill list is not given the reply the user with this message  I am designed to generate JD based on Title and Skill list given , can you please provide required information\\n 1. **Job Title and Summary**:\\n- What are the key responsibilities?\\n 2. **Key Responsibilities**:\\n - Use title and skill proficiency to explain role and resposibilities , dont mention level like (L1), (L2) instead refer if as beginner, intermidiate etc\\n 3. **Qualifications and Skills**:\\n - Skill with highest proficiency should be given more relavance and rest skill as per proficency can be reference accordingly\\n 4. **Experience Requirements**:\\n - How many years of experience are needed?\\n - What type of previous experience is beneficial?\\n - Use proficincy mentioned in skill to explain experience\\n Once JD is created ,update the JD to latest trends in the market\\nand later use web tool provided to fetch latest information/updates on this JD and update accordingly\\n Finally if user ask to summarise the JD the summarise it in 8 to 10 sentinces keeing title , skills with proficiency information intact\", \n",
    "    \"max_output_tokens\": 256,\n",
    "    \"model_name\": \"gpt-4\", \n",
    "    \"temperature\": 0.3,\n",
    "    #\"tools\": [\"BingSearchTool\"],\n",
    "    \"top_k\": 5,\n",
    "    #\"type\": \"Toolset\"\n",
    "    \"type\" : \"Dataset\",\n",
    "    \n",
    "}\n",
    "\n",
    "response = requests.post(agents_endpoint, headers=headers, json=payload)\n",
    "\n",
    "# Print the response from the API call to inspect the result (status code, content, etc.)\n",
    "print(response.json())\n",
    "\n",
    "#'9841fb1c-81f0-4481-aeb6-b77bc7f7ea49' JD Agent2\n",
    "#'8dea253e-4cae-467b-88a5-88df4477c79f'\n",
    "#'owners': ['bf955f58-9ed4-4d5a-9b49-971fc185e5a4']\n",
    "#'tenant_id': 'a919164d-8b7c-43fb-8119-f1997d45ca4f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'name': 'JD_Agent', 'role': 'function', 'content': 'I am designed to generate Job Description based on Title and Skill list given, can you please provide required information?', 'conversation_id': '67ab362910fa7e2d69e30b5d', 'response_status': 'Completed'}}\n"
     ]
    }
   ],
   "source": [
    "# Define the payload (request body) for the API call, which contains the conversation details and instructions for the agent\n",
    "payload = {\n",
    "    \"conversation_id\": \"\",  \n",
    "    \"messages\": [  \n",
    "        {\n",
    "            \"content\": \"I have a job description and I want to enhance it with the latest updates. Can you help me looking in below content and provide me the latest updates?\" + prompt2,  \n",
    "            \"name\": \"Suman\",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    "    \"party_id\": client_id,  # The unique ID of the party (here it is the agent_id which is generated in agents api)\n",
    "    \"party_type\": \"Agent\",\n",
    "    \"save_conversation\": False,  \n",
    "    \"stream_response\": False  \n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(agents_endpoint2, headers=headers, json=payload)\n",
    "\n",
    "# Print the response from the API call to inspect the result (status code, content, etc.)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"As an AI assistant analyzing role clusters, examine the provided job description or skills and:\n",
    "\n",
    "1. **Cluster Matching**:\n",
    "   - Match the input against available role clusters in the dataset\n",
    "   - Rate the match relevancy as a percentage (0-100%)\n",
    "\n",
    "2. **Required Output Format**:\n",
    "   - Cluster Name: [Exact cluster name from dataset]\n",
    "   - Job Grade: [Grade level if available]\n",
    "   - Skills Required: [List of skills from cluster along with Proficiencies]\n",
    "   - Match Percentage: [Calculated relevancy %]\n",
    "   - Practice Type: [e.g., WIPRO PRACTICE]\n",
    "   - Classification: [e.g., PREMIUM, ULTRA PREMIUM]\n",
    "\n",
    "3. **Matching Rules**:\n",
    "   - Consider skill proficiency levels (L1, L2, L3, L4)\n",
    "   - Match role titles and their variations\n",
    "   - Consider skill combinations and their relevance\n",
    "   - Factor in experience level requirements\n",
    "\n",
    "4. **Additional Information**:\n",
    "   - Include any specialized certifications required\n",
    "   - Note any premium/ultra-premium classification\n",
    "   - List related clusters if exact match < 80%\n",
    "\n",
    "Please provide comprehensive cluster information based on the input job description or skills.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"As a skilled Technical Interview Panel with expertise in technology and content writing , your role is to to meticulously evaluate skills and title provided and give detailed Job Description having below points outlined.\n",
    "Use the mentioned skills along with proficiency & title to generate the Job Description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced and L4 means Expert\n",
    "If Title and skill list is not given the reply the user with this message  I am designed to generate Job Description based on Title and Skill list given , can you please provide required information?\n",
    "1. **Job Title and Summary**:\n",
    "- What are the key responsibilities?\n",
    "2. **Key Responsibilities**:\n",
    "- Use title and skill proficiency to explain role and resposibilities , dont mention level like (L1), (L2) instead refer if as beginner, intermidiate etc\n",
    "3. **Qualifications and Skills**:\n",
    "- Skill with highest proficiency should be given more relavance and rest skill as per proficency can be reference accordingly\n",
    "4. **Experience Requirements**:\n",
    "- How many years of experience are needed?\n",
    "- What type of previous experience is beneficial?\n",
    "- Use proficincy mentioned in skill to explain experience\n",
    "Once Job Description is created, update the Job Description with latest trends in the market based on the Web tool to fetch latest information/updates on this Job Description and update highlighting the latest trends\n",
    "Finally if user ask to summarise the Job Description the summarise it in 8 to 10 sentinces keeing title , skills with proficiency information intact\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '8dea253e-4cae-467b-88a5-88df4477c79f', 'allow_all_access': False, 'dataset_id': '617b94b4-65b9-4b93-b465-2a3c8b97bf66', 'instructions': 'As an AI assistant analyzing role clusters, examine the provided job description or skills and:\\n\\n1. **Cluster Matching**:\\n   - Match the input against available role clusters in the dataset\\n   - Rate the match relevancy as a percentage (0-100%)\\n\\n2. **Required Output Format**:\\n   - Cluster Name: [Exact cluster name from dataset]\\n   - Job Grade: [Grade level if available]\\n   - Skills Required: [List of skills from cluster along with Proficiencies]\\n   - Match Percentage: [Calculated relevancy %]\\n   - Practice Type: [e.g., WIPRO PRACTICE]\\n   - Classification: [e.g., PREMIUM, ULTRA PREMIUM]\\n\\n3. **Matching Rules**:\\n   - Consider skill proficiency levels (L1, L2, L3, L4)\\n   - Match role titles and their variations\\n   - Consider skill combinations and their relevance\\n   - Factor in experience level requirements\\n\\n4. **Additional Information**:\\n   - Include any specialized certifications required\\n   - Note any premium/ultra-premium classification\\n   - List related clusters if exact match < 80%\\n\\nPlease provide comprehensive cluster information based on the input job description or skills.', 'max_output_tokens': 4000, 'temperature': 0.2, 'tenant_id': 'a919164d-8b7c-43fb-8119-f1997d45ca4f', 'tools': None, 'type': 'Dataset'}\n"
     ]
    }
   ],
   "source": [
    "#Update Instruction to Agent\n",
    "\n",
    "url = \"https://api.lab45.ai/v1.1/agents/\" + client_id # type: ignore\n",
    "\n",
    "payload = {\n",
    "    \"instructions\": instruction,\n",
    "    \"dataset_id\" : DatasetID2,\n",
    "    \"max_output_tokens\": 4000,\n",
    "    \"temperature\": 0.2,\n",
    "    \"type\": \"Dataset\",\n",
    "    \"tools\": None\n",
    "    #\"tools\": [\"BingSearchTool\"]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Dataset Already in progress , please try after sometime'}\n"
     ]
    }
   ],
   "source": [
    "# Define the payload (request body) for the API call, which includes a dataset ID\n",
    "payload = {\n",
    "        \"dataset_id\": DatasetID2  # The ID of the dataset to be used for the document completion task\n",
    "    }\n",
    "\n",
    "# Make the POST request to the \"prepare\" API endpoint with the provided headers and payload\n",
    "response = requests.post(prepare_endpoint, headers=headers, json=payload)\n",
    "\n",
    "# Print the response from the API call to see the status or data returned\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "qprompt = \"List down premium Clusters...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'content': 'The premium clusters listed in the document are:\\n\\n1. **Techno Functional Consultant Network SDN - L1** - Group B3, NETWORK SDN, WIPRO PRACTICE, ULTRA PREMIUM\\n2. **Solution Architect Data Visualization - L1** - Group C1, DATA VISUALIZATION, WIPRO PRACTICE, PREMIUM\\n3. **Solution Architect .NET Framework - L2** - Group C2, .NET FRAMEWORK, WIPRO PRACTICE, PREMIUM\\n4. **Cyber Security Analyst Security Information Event Management - Splunk - L1** - Group A2, SECURITY INFORMATION EVENT MANAGEMENT - SPLUNK, WIPRO PRACTICE, PREMIUM\\n5. **Techno Functional Consultant Vulnerability Assessment and Penetration Testing - L2** - Group C1, VULNERABILITY ASSESSMENT AND PENETRATION TESTING, WIPRO PRACTICE, PREMIUM\\n6. **Infrastructure Architect Azure-DevOps-Containers - L2** - Group C2, Azure-DevOps-Containers, WIPRO PRACTICE, PREMIUM\\n7. **Solution Architect AIOps - Moogsoft - L2** - Group C2, AIOps - Moogsoft, WIPRO PRACTICE, ULTRA PREMIUM\\n8. **Technical Lead Automotive Cloud Connected Service - L1** - Group B3, Automotive Cloud Connected Service, WIPRO PRACTICE, PREMIUM\\n9. **Senior Consultant - Adv. and Mgmt Information Management Oil and Gas - L1** - Group B3, Information Management Oil and Gas, WIPRO PRACTICE, PREMIUM\\n10. **Managing Consultant - Adv. and Mgmt Upstream Functional Consulting - L1** - Group C2, Upstream Functional Consulting, WIPRO PRACTICE, PREMIUM\\n11. **Techno Functional Consultant Oracle Retail Merchandising - L2** - Group C1, Oracle Retail Merchandising, WIPRO PRACTICE, PREMIUM\\n12. **Developer Mainframe Adabas and Natural - L2** - Group B1, MAINFRAME ADABAS AND NATURAL, WIPRO PRACTICE, SUPER PREMIUM\\n13. **Lead Administrator Image Management - L1** - Group B3, IMAGE MANAGEMENT, WIPRO PRACTICE, PREMIUM\\n\\nThese roles are categorized under various premium levels such as Premium, Super Premium, and Ultra Premium within the Wipro Practice.'}}\n"
     ]
    }
   ],
   "source": [
    "# Define the payload (request body) for the API call, which contains the dataset and skill parameters\n",
    "payload = {\n",
    "        \"dataset_id\" : DatasetId,  \n",
    "        \"skill_parameters\": {  \n",
    "            \"model_name\": \"gpt-4\", \n",
    "            \"retrieval_chain\": \"custom\",  \n",
    "            \"emb_type\": \"openai\",  \n",
    "            \"temperature\": 0,  \n",
    "            \"max_output_tokens\": 1000,  \n",
    "            \"return_sources\": False  \n",
    "        },\n",
    "        \"stream_response\": False, \n",
    "        \"messages\": [  \n",
    "            {\"content\": \"Hi\", \"role\": \"user\"},  \n",
    "            {\"content\": qprompt, \"role\": \"user\"} \n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# Make the POST request to the query API endpoint with the provided headers and payload\n",
    "response = requests.post(query_endpoint, headers=headers, json=payload)\n",
    "\n",
    "# Print the response from the API call to inspect the status or data returned\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "#Uploading the Output file for RAG\n",
    "url = f\"https://api.lab45.ai/v1.1/datasets/{DatasetID2}/ingest\"\n",
    "files = { \"files\": open('ClusterJD.docx', 'rb') }\n",
    "response = requests.post(url, files=files, headers=headers)\n",
    "if response.status_code == 204:\n",
    "\tprint(\"File not uploaded successfully\")\n",
    "else:\n",
    "\tprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
