{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import Extra\n",
    "import requests\n",
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS # type: ignore\n",
    "from langchain_ollama import OllamaEmbeddings # type: ignore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "#os.environ[\"token\"] = \"Bearer token|123675a6-95f6-4fb7-bc95-30095472ae3a|02de311fd83421a7fd637bf34dc8f959caa29f39888d2919e4b9640a2220224b\"\n",
    "token = os.environ[\"TOKEN2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ClassVar\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "class LlamaLLM(LLM):\n",
    "    llm_url: ClassVar[str] = 'https://api.lab45.ai/v1.1/skills/completion/query'\n",
    "    \n",
    "    backend:        Optional[str]   = 'gpt-35-turbo-16k'\n",
    "    temp:           Optional[float] = 0.7\n",
    "    top_p:          Optional[float] = 0.1\n",
    "    top_k:          Optional[int]   = 40\n",
    "    n_batch:        Optional[int]   = 8\n",
    "    n_threads:      Optional[int]   = 4\n",
    "    n_predict:      Optional[int]   = 256\n",
    "    max_tokens:     Optional[int]   = 256\n",
    "    repeat_last_n:  Optional[int]   = 64\n",
    "    repeat_penalty: Optional[float] = 1.18\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gpt-35-turbo-16k\"\n",
    "    \n",
    "    @property\n",
    "    def _get_model_default_parameters(self):\n",
    "        return {\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            #\"n_predict\": self.n_predict,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"temperature\": self.temp,\n",
    "            #\"n_batch\": self.n_batch,\n",
    "            #\"repeat_penalty\": self.repeat_penalty,\n",
    "            #\"repeat_last_n\": self.repeat_last_n,\n",
    "        }\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        user: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "\n",
    "        payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "            \"content\": prompt,\n",
    "            \"role\": user\n",
    "            }\n",
    "        ],\n",
    "        \"skill_parameters\": {\n",
    "            \"model_name\": \"gpt-35-turbo-16k\",\n",
    "            \"max_output_tokens\": 4096,\n",
    "            \"temperature\": 0,\n",
    "            \"top_k\": 5\n",
    "        },\n",
    "        \"stream_response\": False\n",
    "        }\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\",\"Authorization\": token}\n",
    "\n",
    "        response = requests.post(self.llm_url, json=payload, headers=headers, verify=False)\n",
    "\n",
    "       # print(\"API Response:\", response.json())\n",
    "        response.raise_for_status()\n",
    "\n",
    "        return response.json()  # get the response from the API\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"llmUrl\": self.llm_url,\n",
    "            'model_parameters': self._get_model_default_parameters\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LlamaLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_CLUSTER_MASTER = pd.read_csv(r\"D:\\OneDrive - Wipro\\Desktop\\Static Dumps\\Role-Skill-Cluster Master Report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_CLUSTER_MASTER_REQD=ROLE_CLUSTER_MASTER[['CLUSTER_NAME','SKILL_NAME']]\n",
    "ROLE_CLUSTER_MASTER_REQD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = []\n",
    "\n",
    "for i, row in enumerate(ROLE_CLUSTER_MASTER_REQD.itertuples()):\n",
    "  if i > 1001:  \n",
    "    print(i)\n",
    "    skills=row.SKILL_NAME\n",
    "    title=row.CLUSTER_NAME\n",
    "    company=\"Wipro\"\n",
    "    user = \"user\"\n",
    "    prompt = \"\"\" As a skilled Technical Interview Panel with expertise in technology and content writing , your role is to meticulously evaluate skills and title provided and give detailed job description having below points outlined.\n",
    "                Use the mentioned skills along with proficiency  & title to generate the job description, where L1 means Beginner, L2 means Intermediate, L3 means Advanced, and L4 means Expert,\n",
    "                Job Role: \n",
    "                Give skill specified by user\n",
    "                Clearly state the role/title of the position and give brief summary of the role/title in 3-4 lines\n",
    "\n",
    "                Key Responsibilities:\n",
    "                Title/Role will have overall impact on responsibilities\n",
    "                Utilize expertise in [Key Skill 1] and [title/Role] to [Responsibility 1] .\n",
    "                Apply advanced knowledge of [Key Skill 2]  to [Responsibility 2].\n",
    "                Demonstrate proficiency in [Key Skill 3] to [Responsibility 3].\n",
    "                Utilize [Key Skill 4]  to [Responsibility 4].\n",
    "                Apply [Key Skill 5] to [Responsibility 5].\n",
    "\n",
    "                Qualifications and Skills:\n",
    "\n",
    "                Proficiency in [Key Skill 1] is essential for this role, with a strong focus on [Specific Requirement].\n",
    "                Advanced knowledge of [Key Skill 2] is highly desirable, with the ability to [Specific Requirement].\n",
    "                Familiarity with [Key Skill 3] is beneficial, with the capacity to [Specific Requirement].\n",
    "                Experience in [Key Skill 4] is advantageous, with the ability to [Specific Requirement].\n",
    "                Proficiency in [Key Skill 5] is preferred, with the capability to [Specific Requirement].\n",
    "\n",
    "                Experience Requirements:\n",
    "\n",
    "                A minimum of [Number of Years] years of relevant experience in [Industry/Field].\n",
    "                Previous experience in [Specific Type of Experience] is beneficial, with a focus on [Relevant Proficiency].\n",
    "                Demonstrated proficiency in [Key Skill 1] and [Key Skill 2] through [Type of Experience].\n",
    "                Proven track record of applying [Key Skill 3] and [Key Skill 4] in [Type of Experience].\n",
    "\n",
    "                \"\"\" + skills + title + company # type: ignore\n",
    "    result = llm._call(prompt,user)\n",
    "    parsed_result = result['data']['content'] # type: ignore\n",
    "    JD.append(\"CLUSTER NAME :\"+title +'\\n'+\"CLUSTER SKILLS : \"+skills+'\\n'+parsed_result+'\\n'+'\\n'+'\\n'+'\\n') # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in JD:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outfilenew\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(JD))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
